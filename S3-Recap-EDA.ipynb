{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44744c5-18b5-4fc9-8f34-74e67145d3ed",
   "metadata": {},
   "source": [
    "# Récap : Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f389e58-991c-4075-af71-51f00cddd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072cb7aa-0977-4ce1-b39e-72fa34f413c4",
   "metadata": {},
   "source": [
    "## Processus analyse de données / création modèle ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c351dc-f13a-4d6a-ac19-f3761c311be2",
   "metadata": {},
   "source": [
    "1. Récupérer les données brutes (.csv, API/JSON, BDD/SQL,…)\n",
    "2. Parcourir les données, prendre connaissance des colonnes/variables et **réaliser une copie de travail**\n",
    "3. Statistiques descriptives : moyenne, médiane, max, min, écart-type, quantiles, variance, covariances, corrélation…\n",
    "4. Nettoyage : gérer les ```NaN``` (suppression ? remplacement par moyenne, médiane ?), convertir les autres valeurs problématiques comme ```inf``` et ```-inf```, supprimmer des colonnes (inutiles, non exploitables)\n",
    "5. Si besoin, assembler les données (merge), créer les métriques qui nous manquent (créer de nouvelles colonnes, transformer…)\n",
    "6. Visualiser les données (distribution, mise en relation) avec des graphes adaptés au types de données (bar plots, scatter plots, cat plots, box plots…)\n",
    "7. Repérer et gérer les outliers (supprimer ou transformer)\n",
    "8. Choisir, entraîner et tester des modèles de ML ou analyse (inférence statistique)\n",
    "9. Amélioration des modèles (fine-tuning, feature selection) et comparaison des modèles les mieux ajustés (A/B testing)\n",
    "10. Déploiement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d237cf3-14bb-4879-bedf-f63f8d7379c6",
   "metadata": {},
   "source": [
    "## Récap : outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db817f-d65f-4822-819e-d5b3b236a069",
   "metadata": {},
   "source": [
    "### Outliers : definition\n",
    "\n",
    "[Article « Donnée aberrantes sur Wikipédia](https://fr.wikipedia.org/wiki/Donn%C3%A9e_aberrante) :\n",
    "\n",
    "> « En statistique, une donnée aberrante (anglais outlier) est une valeur ou une observation qui est « distante » des autres observations effectuées sur le même phénomène, c'est-à-dire qu'elle contraste grandement avec les valeurs « normalement » mesurées. Une donnée aberrante peut être due à la variabilité inhérente au phénomène observé, ou indiquer une erreur expérimentale. Dans ce dernier cas, elles sont parfois écartées.\n",
    "\n",
    "> […]\n",
    "\n",
    "> Une interprétation statistique naïve d'une série de données contenant des données aberrantes peut être trompeuse et induire en erreur. Par exemple, si une personne décide de calculer la température moyenne de 10 objets dans une pièce, et que 9 d'entre eux ont une température située entre 20 et 25 degrés Celsius mais que le dernier est un four en marche à 175 °C, la médiane de la série sera située entre 20 et 25 °C mais la température moyenne sera entre 35,5 et 40 °C. Dans ce cas, la médiane est un meilleur indicateur de la température des objets que la moyenne. »\n",
    "\n",
    "![Normal distribution with standard deviation](./images/Empirical_Rule.PNG)\n",
    "\n",
    "By Dan Kernler - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=36506025\n",
    "\n",
    "Dans le cas du four donné en exemple ci-dessus, la valeur aberrante est dû au fait qu’elle est produite par une autre « règle » ou un autre « phénomène » que celui qu’on recherche (four allumé vs. chaleur ambiante). C’est ce que l’on pourrait considérer comme une erreur de mesure. \n",
    "Une autre catégorie d’outlier sont des valeurs « naturelles », mais très rares (un salaire de 100 k€ par mois, ou un bébé de 7kg à la naissance, ou encore un homme d’une taille de 2,4m – penser à tous les records).\n",
    "\n",
    "Les outliers peuvent avoir de nombreux effets négatifs :\n",
    "\n",
    "- influencer négativement l’estimation des distributions et autres patterns sous-jacent aux données (distribution avec une queue plus large que la réalité, moyennes « décalées », etc.)\n",
    "- variance observée (et erreur) plus importante\n",
    "- certains modèles (comme la régression traditionnelle) sont très sensibles aux outliers, l’estimation devient moins fiable / stable\n",
    "- des modèles de ML peuvent faire du surapprentissage sur des données aberrantes, les identifiant comme des données singulièrement importantes et de nouvelles données sans outliers n’étant pas traitées correctement\n",
    "\n",
    "Les outliers peuvent être de différents types :\n",
    "- ne concerner qu’une seule variable (dû à une erreur de mesure systématique ou exceptionnelle)\n",
    "- des combinaisons (patterns) de variables assez rare, mais pour lequel on n’arrive pas à capturer l’élément explicatif (par exemple faible niveau d’étude mais hauts revenus : héritage, footballeur – haut niveau de formation mais pas au sens classique, etc.)\n",
    "- des mesures effectuées dans des contextes particuliers : on voit une concentration d’outliers pour une location, ou une date donnée qui tranche avec le reste des observation, ici aussi il nous manque un évènement qui a dû survenir pour expliquer le pattern \n",
    "\n",
    "La question est : que fait-on des outliers ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae2053-d8f0-40a6-8f61-8a624affffee",
   "metadata": {},
   "source": [
    "### Repérer les outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff804e6d-6cbe-461c-bfa9-9dea631aaa6e",
   "metadata": {},
   "source": [
    "Une première chose à faire est de les repérer. La boîte à moustache nous permet d’en apprécier visuellement le nombre et la distribution (sont ils rares ? quand il y en a sont-ils très loin de la limite ?). Pour les traiter, nous devons construire des fonctions qui nous permettront de les repérer et de les trier dans nos données. On peut envisager différentes approches :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb8ae8-6a30-4ffc-bfe4-06a39e0f0e8d",
   "metadata": {},
   "source": [
    "#### Repérer les outliers à l’aide des IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751c7c9-7a74-49c7-bff4-39a143c446fd",
   "metadata": {},
   "source": [
    "C’est une approche assez universelle, qui fonctionne même pour des distributions légèrement dissymétriques (« à queue épaisse » / *skewed*), et correspond à ce que montre les boîtes à moustache :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85bafa02-e70d-47c9-ae03-ce8d59ab87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répérer les outliers à partir des IQR\n",
    "def IQR_outliers(df_col: pd.Series) -> tuple:\n",
    "    Q1 = df_col.quantile(0.25)\n",
    "    Q3 = df_col.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_sup = Q3 + 1.5 * IQR\n",
    "    limite_inf = Q1 - 1.5 * IQR\n",
    "\n",
    "    return (limite_inf, limite_sup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f163c-2898-4ea8-be53-52794ffab5ff",
   "metadata": {},
   "source": [
    "Un simple boolean indexing nous permet ensuite d’analyser séparément les données avec ou sans outlier :\n",
    "\n",
    "```python\n",
    "sup, inf = IQR_outliers(df.col) \n",
    "df_sans_outliers = df[((df.col < sup) & (df.col > inf))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7476c00-6d97-451a-bd8a-e6305c66b1f7",
   "metadata": {},
   "source": [
    "#### Repérer les outliers à partir des écarts-types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb7095-129d-4479-932f-5b4e7c221926",
   "metadata": {},
   "source": [
    "On peut fixer une limite en matière d’écart-type (par exemple fixer la limite à 3 écart-types). Cette méthode fonctionne bien pour les distributions normales  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e71b76a0-b016-4beb-af20-e410dc1d481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd_outliers(df_col : pd.Series) -> tuple:\n",
    "    seuil = 3 # on peut aussi mettre le seuil en argument de la fonction\n",
    "    limite_sup = df_col.mean() + seuil * df_col.std()\n",
    "    limite_inf = df_col.mean() - seuil * df_col.std()\n",
    "\n",
    "    return (limite_inf, limite_sup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2801614-e6e1-4161-abd4-24cb609f059d",
   "metadata": {},
   "source": [
    "#### Repérer les outliers à partir du z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0d56c-4528-4fae-b3d8-f5053afbf0d3",
   "metadata": {},
   "source": [
    "On peut aussi fixer une limite par rapport à la position dans la distribution, grâce au z-score :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb534835-1532-4f13-b604-1cdc01ce5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "def z_outliers(df: pd.DataFrame, threshold: float) -> tuple:\n",
    "    z_scores = np.abs(zscore(df))\n",
    "    return df[(z_scores < threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f3365-325a-435f-934a-ccbdc2c1d6df",
   "metadata": {},
   "source": [
    "#### Autres méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1eb2ca-bc74-48c9-826f-b19b6a67d624",
   "metadata": {},
   "source": [
    "Dans certains cas, on peut aller plus loint dans l’élaboration des techniques pour identifier les outliers. Par exemple on peut choisir une distribution de référence (si l’on sait que nos données obéissent à cette loi), et estimer un seuil de probabilité pour cette distribution au delà de laquelle on considère que l’observation est trop improbable pour avoir eu lieu (c’est un peu ce que l’on fait ci-dessus avec des distribution normales). Mais on peut aussi utiliser des algorithmes de machine learning comme le k-mean clustering, et considérer que certaines observations qui sont trop éloignés des clusters qui auront été identifiés sont des outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031cd226-ee31-4dee-98c3-996b750ff5e6",
   "metadata": {},
   "source": [
    "### Gérer les outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8d9f0-afa3-4e9c-8ae2-e4b03ca983c2",
   "metadata": {},
   "source": [
    "1. Les supprimer simplement et proprement. La taille de l’échantillon est réduite, ce qui peu parfois poser problème.\n",
    "2. Les « winsoriser » (du nom du bio-statisticien [Charles Winsor](https://en.wikipedia.org/wiki/Charles_Winsor)). Il s’agit de remplacer (et non de supprimer) la valeur des outliers par des seuils (ou des plafonds). Par exemple si dans un ensemble de données qui s’étendent entre 12 (min) et 52 (max) on estime que les valeurs au dessus du 95e percentile sont des outliers, et que ce percentile commence à la valeur 43 par exemple, on va rammener toutes les valeurs au dessus de 43 à 43. Attention le processus doit être symétrique : il faut faire de même avec le 5e percentile, tout en étant vigilant car il faut modifier le même nombre de données de chaque côté de la distribution (ce qui peut n’être pas le cas si on ne considère que les percentiles, quand plusieurs données on la même valeur). La taille de l’échantillon reste intacte.\n",
    "3. Appliquer des transformations qui « normalisent » les distributions, comme des fonctions logarithmes, des fonctions racines, etc. Mais il faut avoir de bonnes raisons de le faire.\n",
    "4. Normaliser les données : parfois la normalisation (z-score) ramène l’essentiel des observations dans l’intervalle -3/+3 s.d., et les outliers se retrouvent à une « juste » place où leur influence est atténuée (en valeur absolue)\n",
    "5. Mettre en œuvre des modèles qui sont réputés plus [robustes](https://en.wikipedia.org/wiki/Robust_regression) à l’influence des outliers que les modèles classiques (les mégthodes d’estimation comme l’OLS y est très sensible).\n",
    "\n",
    "Dans tous les cas il faut être très prudent dans la gestion des outliers : on modifie des données qui rendent compte de la forme des distribution, notamment les queues, or elles peuvent jouer un rôle important dans les analyses statistiques que l’on veut mener (condition d’application, hypothèses…). C’est pour cela que notre décision dépend aussi du type d’outlier (cf. liste plus haut) qui vont conduire à des actions différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4366bac-531a-42b2-997b-2fc37cf421b2",
   "metadata": {},
   "source": [
    "## Valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c968d6-b450-43f5-ab13-4f5328b91654",
   "metadata": {},
   "source": [
    "Les valeurs manquantes peuvent avoir les même conséquences que les outliers sur nos analyses (mauvaise estimation de la distribution, mauvaise estimation des paramètres d’un modèle, effets sur la variance, etc.), mais aussi deux autres effets négatifs :\n",
    "\n",
    "- souvent les valeurs manquantes obéissent à un pattern (recueil de données défectueux, accident, difficultés en un lieu, une date, une cible, en particulier). Si ce pattern n’est pas explicité, il peut contaminer le modèle ou les analyses qui vont mal refléter la réalité (biais statistique)\n",
    "- s’il manque des données, c’est comme si notre échantillonage n’était pas complet, et donc entame notre capacité à faire ressortir ou identifier dans nos analyses des relations significatives entre les variables (perte de puissance statistique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf8f2e-8aee-4366-a20a-ac84e89e0182",
   "metadata": {},
   "source": [
    "#### Type de valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ef953-998c-4c21-867e-d7c04aebe8fd",
   "metadata": {},
   "source": [
    "1. des valeurs qui manquent de manière totalement aléatoire (incident dans un recueil ou la copie d’une donnée)\n",
    "2. des valeurs qui manquent de manière aléatoire (n’importe quelle valeur peu manquer), mais en fonction de la valeur d’une autre variable, qui elle est connue\n",
    "3. des valeurs qui manquent de non aléatoire (ce sont juste des valeurs données qui peuvent manquer, par exemple on ne peut pas enregistrer des valeurs supérieur à 10 et cette variable a eu des valeurs supérieures à 10)\n",
    "4. des valeurs manquante pour des questions (souvent dans les questionnaires), des mesures, ou encore des variables précises au sein des observations\n",
    "5. des enregistrement entiers qui manquent (pas seulement quelques variables, mais une ligne complète), par exemple un questionnaire rendu vide\n",
    "\n",
    "On constate qu’encore plus que pour les outliers, le contexte et le type de la valeur manquante vont être très importants pour choisir le traitement adapté. D’ailleurs pour plusieurs cas, à ce niveau du cours, nous n’avons pas les connaissances nécessaires pour mettre en œuvre certaines solutions. On les présente ici juste à titre documentaire. Y revenir quand vous serez mieux outillés en matière de statistiques et de modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0b7f8-af30-4313-9886-f221e5db2d1f",
   "metadata": {},
   "source": [
    "#### Gérer les valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1809d5d-6091-489f-af05-d5ed058b124f",
   "metadata": {},
   "source": [
    "Comme pour les outliers, il y a deux stratégies : la suppression ou le remplacement.\n",
    "\n",
    "1. supprimer tout enregistrement (ligne) où une valeur est manquante, avec la méthode ```df.dropna()```. Solution radicale, mais qui risque de diminuer drastiquement la taille de l’échantillon\n",
    "2. pour les valeurs manquantes totalemenet aléatoires (le cas (1) dans la liste ci-dessus), une bonne technique est de remplacer la valeur manquante par la moyenne ou le mode (la valeur la plus fréquente) de la variable concernée. On appelle ça une imputation. On peut le faire à la main (définir une fonction qui remplace les valeurs manquantes par, au choix, la moyenne ou le mode), mais la bibliothèque de machine learning [Scikit-Learn](https://scikit-learn.org/stable/index.html) dispose de tout un ensemble de méthodes pour cela – module ```sklearn.inpute```. Vous verrez cela dans le module machine learning, pour le moment on fera ces remplacements « à la main ». Cette technique est problématique par contre dans les situations où les valeurs manquantes sont liées à une autre variable (cas (2) et (3) ci-dessus).\n",
    "3. si on suspecte un pattern derrière les valeurs manquantes, on peut envisager de créer un modèle qui va permettre, à partir des valeurs que prennent les autres variables observées, de recréer les valeurs supposées de la variable qui fait défaut. On peut utiliser un modèle de régression, de corrélation, ou des modèles qui reconstruisent la distribution de la valeur manquante. Des modèles de clustering peuvent aussi intevenir (en repérant d’autres enregistrements qui « ressemblent » à celui où la valeur est absente, mais où elle est présente par contre et où on la recopiera). Il y a d’autres modèles plus complexes adaptés à cet objectif : *multivariate imputation through chained equations, pattern mixture model, predictive mean matching*…\n",
    "\n",
    "Pour ce cours d’introduction on se limitera aux deux premières solutions.\n",
    "Quelques conseils : d’abord rechercher si l’absence de valeur obéit à un pattern, la situation la plus favorable étant que ces absences soit totalement aléatoires. Ensuite se demander si la variable affectée est importante pour notre analyse ou pas (inutile de perdre du temps pour rien, avec une mesure de mauvaise qualité). C’est là que la connaissance métier, ou la connaissance du domaine est importante. De la même manière, ne pas négliger la recherche d’outlier, cette inspection des données doit être systématique et effectuée assez tôt dans l’exploration des données.\n",
    "\n",
    "**Gardez bien une trace de toutes les manipulations que vous effectuez**\n",
    "Vous aurez vraissemblablement à appliquer différentes méthodes : élimination dans certains, remplacement par des moyennes, idem pour les outliers, etc. Le nettoyage étant lui aussi un processus itératif, il est extrêmement important de rendre vos traitement reproductibles, et traçables (savoir ce que vous avez fait, dans quel ordre…). Donc conserver des logs !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f44a2-7a4e-4db9-bc3e-ee2e64d541c4",
   "metadata": {},
   "source": [
    "## Exercices / Exemples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28280b1d-7a2c-4d57-9dfd-7b87bd0a3ca6",
   "metadata": {},
   "source": [
    "*Vous n’êtes pas obligés de faire les explorations dans l’ordre : suivez votre inspiration. Mais essayez de tout faire : plus vous explorerez de situations différentes, plus vous serez familier avec ces manipulations.*\n",
    "\n",
    "Voici quelques jeux de données mis à disposition librement, et qui peuvent servir de support pour mettre en œuvre les techniques d’EDA :\n",
    "\n",
    "1. Synthétisez les données avec des statistiques descriptives\n",
    "2. Repérez si ces données doivent être nettoyées (valeurs manquantes ? outliers ?)\n",
    "3. Repérez des corrélations, regardez si vous pouvez faire émerger des patterns par de simples visualisations\n",
    "4. N’hésitez pas à simplifier le problème en faisant des hypothèses sur les variables qui vous semblent « à retenir » (lisez bien les métadonnnées si elles sont disponibles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9583c1-18d8-4cb1-b80a-e230d3cfcc8d",
   "metadata": {},
   "source": [
    "### Jeu de données 1 : house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5035b7-910e-4dcb-9aef-76ff466560d4",
   "metadata": {},
   "source": [
    "Le prix de vente de biens immobiliers et de nombreuses variables :\n",
    "[house prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "Ce jeux de données est proposé dans le cadre d’un sujet de machine learning, nous n’irons pas aussi loin. Nous nous contenterons d’explorer ces données. Aussi seuls trois fichiers nous intéressent : train.csv et test.csv qu’il faudra assembler en un seul dataframe de données, et le fichier texte qui l’accompagne pour bien comprendre les données, ce qui vous permettra de formuler des hypothèses pour orienter votre exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5e0eb-445f-420d-a009-5af4a801f885",
   "metadata": {},
   "source": [
    "### Jeu de données 2 : loan predication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db72c52-2145-472c-93fa-3706c6a9ca5e",
   "metadata": {},
   "source": [
    "Voilà un jeu de données intéressant pour étudier la questions des outliers, des transformations de distributions… [loan predication](https://www.kaggle.com/datasets/ninzaami/loan-predication/data)\n",
    "\n",
    "Le problème est de mettre en relation des caratéristiques d’individus, et la susceptibilité de leur attribuer un prêt.\n",
    "\n",
    "Réalisez toutes les explorations demandées, mais notez qu’à un moment, selon ce que vous observerez graphiquement, ce jeu de données se prête bien à une transformation par une fonction logarithme ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01fe9a-4164-4b74-b6a5-ede53d7c82a7",
   "metadata": {},
   "source": [
    "### Jeu de données 3 : pétrole brut et gaz naturel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da389711-a29b-4925-823c-ca2f4bbf2dff",
   "metadata": {},
   "source": [
    "Ce jeu de données indique la production US de gaz et de pétrole de juin 2008 à juin 2018 : [us-oil-and-gas-production](https://www.kaggle.com/datasets/djzurawski/us-oil-and-gas-production-june-2008-to-june-2018)\n",
    "\n",
    "Ces données font intervenir des informations temporelles.\n",
    "\n",
    "En plus des explorations classiques ce jeu de données à pour intérêt :\n",
    "\n",
    "* il vous faudra convertir des objects (string) en timestamp pour pouvoir exploiter ces données\n",
    "* avec des ```.groupby()``` essayez de calculer et représenter les productions annuelles de gaz et de pétrole\n",
    "* de même présentez graphiquement la production par États\n",
    "* assemblez en un seul dataframe synthétique, par année, la production de gaz **et** de pétrole, pour l’ensemble des US seulement, et un autre, État par État."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14158ab9-ee0f-4ec3-9824-fc6285a0e8ff",
   "metadata": {},
   "source": [
    "### Jeu de données 4 : émissions de CO2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd87d847-d025-4d82-8644-332b19c8dbea",
   "metadata": {},
   "source": [
    "Ce jeu de données répertorie pour des véhicules de différents modèles la quantité de CO2 émise : [vehicle-co2-emissions-dataset](https://www.kaggle.com/datasets/brsahan/vehicle-co2-emissions-dataset/data)\n",
    "\n",
    "L’occasion de faire quelques visualisation très informatives !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547d611-2ec8-47ed-af81-5f65de4c48af",
   "metadata": {},
   "source": [
    "### Jeu de données 5 : des vraies données bien sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f829a-cd20-4c3d-9f7e-b49961ef8d54",
   "metadata": {},
   "source": [
    "Si vous trouvez les jeux de données précédents trop simples et qu’ils ne demandent pas assez de travail de nettoyage, etc., voici un jeu de données (réelles) qui vous donnera plus de fil à retordre : [Olist dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)\n",
    "\n",
    "Un bon exercice pour apprendre à merger des données, et à créer des métriques.\n",
    "\n",
    "1. Observez bien le schéma de la base de données\n",
    "2. Essayez à partir de là de créer un dataframe unique (il va falloir faire des ```.merge(), .groupby()```, etc.) qui contient toutes les données intéressantes, selon des hypothèses que vous pourrez faire : par exemple, y a-t-il une corrélation entre la vitesse à laquelle un consommateur reçoit un produit et l’appréciation qu’il laisse à un vendeur ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece24d5-fa4f-4101-b075-98ce22a40d9b",
   "metadata": {},
   "source": [
    "### Présentez un jeu de données qui a attiré votre intérêt pour le projet de ce module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33f86b-960f-4b27-82b1-7469c3dedc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
